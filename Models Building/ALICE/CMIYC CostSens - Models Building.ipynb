{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efca6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_row\",999)\n",
    "pd.set_option(\"display.max_column\",999)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split,learning_curve\n",
    "from sklearn.metrics import (f1_score, confusion_matrix, classification_report, matthews_corrcoef, roc_curve, \n",
    "                             roc_auc_score,accuracy_score, recall_score, precision_score, precision_recall_curve,\n",
    "                             cohen_kappa_score, log_loss )\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN  \n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942197c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a81685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train_sessions.csv\")\n",
    "print('train',df.shape)\n",
    "df=df.sort_index(axis=1)\n",
    "\n",
    "df=df[['session_id','site1','site10','site2','site3','site4','site5','site6','site7','site8','site9','target']]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col_obj in df.select_dtypes(\"object\").columns: \n",
    "    df[col_obj] = pd.to_datetime(df[col_obj], format='%Y-%m-%d')\n",
    "\n",
    "print(df.shape)\n",
    "df=df[df.columns[df.isna().sum()/df.shape[0]<0.2]]\n",
    "print(df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "for col_obj in df.select_dtypes(\"object\").columns: \n",
    "    lb=LabelEncoder()\n",
    "    df[col_obj]=lb.fit_transform(df[col_obj]) \n",
    "df=df.rename(columns={'target':'Class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit_data = credit_data.sample(n=20000, random_state=0) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ba27b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie((df['Class']).value_counts(), labels=(df['Class']).value_counts().index, \n",
    "        autopct='%1.1f%%', startangle=140, \n",
    "        colors=['#66b3ff','#99ff99','#ffcc99','#c2c2f0'])\n",
    "plt.title('Distribution of Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb697acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(df.columns)\n",
    "cols.remove('Class')\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in cols:\n",
    "    df_cleaned = remove_outliers_iqr(df, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ac621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of outliers detected:\n",
    "df.shape[0]-df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd27f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('% des class Original:\\n',(df['Class']).value_counts().sort_values(ascending=False))\n",
    "\n",
    "print('% des class cleaned:\\n',(df_cleaned['Class']).value_counts().sort_values(ascending=False))\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie((df_cleaned['Class']).value_counts(), labels=(df_cleaned['Class']).value_counts().index, \n",
    "        autopct='%1.1f%%', startangle=140, \n",
    "        colors=['#66b3ff','#99ff99','#ffcc99','#c2c2f0'])\n",
    "plt.title('Distribution of Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[df_cleaned['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19846244",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cleaned.columns),df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8849b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop(\"Class\", axis=1)\n",
    "y = df_cleaned[\"Class\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ee0b96b",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "print('% des class:\\n',(y_rus).value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "print('% des class:\\n',(y_ros).value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ea181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=0)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "print('% des class:\\n',(y_smote).value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ab632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid method using SMOTE and Edited Nearest Neighbors (SMOTEENN)\n",
    "smoteenn = SMOTEENN(random_state=0)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_resample(X, y)\n",
    "print('% des class:\\n',(y_smoteenn).value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f119cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Borderline SMOTE resampler\n",
    "bsmote = BorderlineSMOTE(random_state=0)\n",
    "X_bsmote, y_bsmote = bsmote.fit_resample(X, y)\n",
    "print('% des class:\\n', y_bsmote.value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d27c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ADASYN resampler\n",
    "adasyn = ADASYN(random_state=0)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)\n",
    "print('% des class:\\n', y_adasyn.value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "583c346a",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06460dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,name,X,y):\n",
    "    print('\\n===================================',name,' - GridSearchCV ===================================')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    # Convert both sets to sets to get unique values\n",
    "    train_set_unique = np.array(X_train)\n",
    "    test_set_unique = np.array(X_test)\n",
    "    \n",
    "    # Check if both sets have the same samples\n",
    "    if np.array_equal(train_set_unique, test_set_unique):\n",
    "        print(\"Train set and test set have the same samples.\")\n",
    "    else:\n",
    "        print('X_train shape: ',X_train.shape, 'y_train shape: =', y_train.shape)\n",
    "        print('% des class dans Y train:')\n",
    "        print((y_train).value_counts().sort_values(ascending=False))\n",
    "        print('% des class dans Y test:')\n",
    "        print((y_test).value_counts().sort_values(ascending=False))\n",
    "        \n",
    "        class_counts = np.bincount(y_train)\n",
    "        total_samples = len(y_train)\n",
    "        class_weights = [{i: total_samples / (len(class_counts) * count)} for i, count in enumerate(class_counts)]\n",
    "        param_grid = {'class_weight': class_weights}\n",
    "        scoring = {'matthews_corrcoef': make_scorer(matthews_corrcoef),} \n",
    "        grid_search = GridSearchCV(model, param_grid, scoring=scoring, refit='matthews_corrcoef')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        model = grid_search.best_estimator_\n",
    "        \n",
    "        # Saving the model\n",
    "        pickle.dump(model, open(f'{name}.pkl', 'wb'))\n",
    "        \n",
    "        ypred = model.predict(X_test)\n",
    "        # print(\"Train set and test set have different samples.\")\n",
    "        print('\\n ------------------------------------------------------------------------------------------- ')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, ypred).ravel()\n",
    "        print(f\"{'matthews_corrcoef': <40}{matthews_corrcoef(y_test, ypred)*100}\")\n",
    "        print(f\"{'f1_score': <40}{f1_score(y_test, ypred)*100}\")\n",
    "        print(f\"{'accuracy_score': <40}{accuracy_score(y_test, ypred)*100}\")\n",
    "        print(f\"{'recall_score': <40}{recall_score(y_test, ypred)}\")\n",
    "        print(f\"{'precision_score': <40}{precision_score(y_test, ypred)}\")\n",
    "        print(f\"{'roc_auc_score': <40}{roc_auc_score(y_test, ypred)}\")\n",
    "        print(f\"{'false_positive_rate': <40}{fp / (fp + tn)}\")\n",
    "        print(f\"{'negative_predictive_value': <40}{tn / (tn + fn)}\")\n",
    "        print(f\"{'confusion_matrix'}\\n{confusion_matrix(y_test, ypred)}\")\n",
    "        print(f\"{'classification_report'}\\n{classification_report(y_test, ypred)}\")\n",
    "        # cross validation:\n",
    "        N, train_score, val_score = learning_curve(model,X_train,y_train,cv=5,scoring='f1',\n",
    "                                                   train_sizes=np.linspace(0.1, 1, 10))\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, ypred)\n",
    "\n",
    "        # Affichage\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))  \n",
    "        axes[0].plot(N, train_score.mean(axis=1), label='train score')\n",
    "        axes[0].plot(N, val_score.mean(axis=1), label='validation score')\n",
    "        axes[0].legend()\n",
    "        axes[1].set_title('Learning Curve')  \n",
    "        axes[1].plot([0, 1], [0, 1], 'k--', label = 'Base')\n",
    "        axes[1].plot(fpr, tpr, color = 'blue', label = 'ROC')\n",
    "        axes[1].set_xlabel('False Positive Rate')\n",
    "        axes[1].set_ylabel('True Positive Rate')\n",
    "        axes[1].set_title('ROC Curve')\n",
    "        axes[1].legend(loc='best')\n",
    "\n",
    "        plt.tight_layout()  \n",
    "        plt.show()  \n",
    "        fig.savefig(f\"CMIYC_{name}.jpg\", bbox_inches='tight', dpi=1000)\n",
    "        print('===================================================================================================================')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baff7dcd",
   "metadata": {},
   "source": [
    "#  LR, DT, RF, XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf46ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "LR  = LogisticRegression()\n",
    "DT  = DecisionTreeClassifier(random_state=0)\n",
    "RF  = RandomForestClassifier(random_state=0)\n",
    "XGB = xgb.XGBClassifier(objective='binary:logistic', random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71dc6467",
   "metadata": {},
   "source": [
    "# RUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c82817",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_RUS', X_rus, y_rus)\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_RUS', X_rus, y_rus)\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_RUS', X_rus, y_rus)\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_RUS', X_rus, y_rus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "899fc48e",
   "metadata": {},
   "source": [
    "# ROS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_ROS', X_ros, y_ros)\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_ROS', X_ros, y_ros)\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_ROS', X_ros, y_ros)\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_ROS', X_ros, y_ros)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7301f141",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_SMOTE', X_smote, y_smote)\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_SMOTE', X_smote, y_smote)\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_SMOTE', X_smote, y_smote)\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_SMOTE', X_smote, y_smote)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f65ce5",
   "metadata": {},
   "source": [
    "# SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_SMOTEENN', X_smoteenn, y_smoteenn)\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_SMOTEENN', X_smoteenn, y_smoteenn)\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_SMOTEENN', X_smoteenn, y_smoteenn)\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_SMOTEENN', X_smoteenn, y_smoteenn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309832d",
   "metadata": {},
   "source": [
    "# BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_BSMOTE', X_bsmote, y_bsmote)\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_BSMOTE', X_bsmote, y_bsmote)\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_BSMOTE', X_bsmote, y_bsmote)\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_BSMOTE', X_bsmote, y_bsmote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71da6cb",
   "metadata": {},
   "source": [
    "# ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(LR, 'CMIYC_LogisticRegression_ADASYN', X_adasyn, y_adasyn )\n",
    "evaluation(DT, 'CMIYC_DecisionTreeClassifier_ADASYN', X_adasyn, y_adasyn )\n",
    "evaluation(RF, 'CMIYC_RandomForestClassifier_ADASYN', X_adasyn, y_adasyn )\n",
    "evaluation(XGB, 'CMIYC_XGBClassifier_ADASYN', X_adasyn, y_adasyn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef64260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
